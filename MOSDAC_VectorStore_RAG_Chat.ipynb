{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4513effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "\n",
    "# LangChain and ML imports\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader, UnstructuredHTMLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Visualization imports (optional)\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7eaac140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Model configuration - using cost-effective model\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "\n",
    "# Verify API key is loaded\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"‚ö†Ô∏è Warning: OpenAI API key not found!\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "495527db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document loading functions for different platforms\n",
    "def load_txt_folder(path, site_tag):\n",
    "    \"\"\"Load text files from a directory\"\"\"\n",
    "    try:\n",
    "        loader = DirectoryLoader(\n",
    "            path=path,\n",
    "            glob=\"**/*.txt\",\n",
    "            loader_cls=lambda p: TextLoader(p, encoding=\"utf-8\")\n",
    "        )\n",
    "        docs = loader.load()\n",
    "        for d in docs:\n",
    "            d.metadata[\"source_site\"] = site_tag\n",
    "        print(f\"‚úÖ Loaded {len(docs)} TXT files from {site_tag}\")\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading TXT from {path}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def load_html_folder(path, site_tag):\n",
    "    \"\"\"Load HTML files from a directory\"\"\"\n",
    "    try:\n",
    "        loader = DirectoryLoader(\n",
    "            path=path,\n",
    "            glob=\"**/*.html\",\n",
    "            loader_cls=UnstructuredHTMLLoader\n",
    "        )\n",
    "        docs = loader.load()\n",
    "        for d in docs:\n",
    "            d.metadata[\"source_site\"] = site_tag\n",
    "        print(f\"‚úÖ Loaded {len(docs)} HTML files from {site_tag}\")\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading HTML from {path}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def load_pdf_folder(path, site_tag):\n",
    "    \"\"\"Load PDF files from a directory\"\"\"\n",
    "    try:\n",
    "        loader = DirectoryLoader(\n",
    "            path=path,\n",
    "            glob=\"**/*.pdf\",\n",
    "            loader_cls=PyPDFLoader\n",
    "        )\n",
    "        docs = loader.load()\n",
    "        for d in docs:\n",
    "            d.metadata[\"source_site\"] = site_tag\n",
    "        print(f\"‚úÖ Loaded {len(docs)} PDF files from {site_tag}\")\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading PDF from {path}: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cad54aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Directory ready: data_ingestion/mosdac_data/documents\n",
      "üìÅ Directory ready: data_ingestion/mosdac_data/web_pages\n",
      "üìÅ Directory ready: data_ingestion/vedas_data/web_pages\n",
      "üìÅ Directory ready: data_ingestion/bhuvan_data/web_pages\n",
      "\n",
      "üîÑ Loading documents from all platforms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x30f8cb for key /Im1027\n",
      "Multiple definitions in dictionary at byte 0x30f8dc for key /Im1027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 1265 PDF files from mosdac\n",
      "‚úÖ Loaded 220 TXT files from mosdac\n",
      "‚úÖ Loaded 0 HTML files from mosdac\n",
      "‚úÖ Loaded 233 TXT files from vedas\n",
      "‚úÖ Loaded 0 HTML files from vedas\n",
      "‚úÖ Loaded 6 TXT files from bhuvan\n",
      "‚úÖ Loaded 0 HTML files from bhuvan\n",
      "\n",
      "üìä Total documents loaded: 1724\n",
      "üìã Sample metadata: {'producer': 'Nitro PDF PrimoPDF', 'creator': 'PrimoPDF http://www.primopdf.com', 'creationdate': '2012-03-20T14:49:18-05:30', 'moddate': '2012-03-20T14:49:18-05:30', 'title': 'Microsoft Word - Analysed-Winds', 'author': 'admin', 'source': 'data_ingestion\\\\mosdac_data\\\\documents\\\\Analysed-Winds.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1', 'source_site': 'mosdac'}\n",
      "üìà Documents by platform:\n",
      "   MOSDAC: 1485 documents\n",
      "   VEDAS: 233 documents\n",
      "   BHUVAN: 6 documents\n"
     ]
    }
   ],
   "source": [
    "# Root folders ‚Äì create directories if they don't exist\n",
    "ROOT_MOSDAC_PDF = \"data_ingestion/mosdac_data/documents\"\n",
    "ROOT_MOSDAC_WEB = \"data_ingestion/mosdac_data/web_pages\"\n",
    "ROOT_VEDAS_WEB = \"data_ingestion/vedas_data/web_pages\"\n",
    "ROOT_BHUVAN_WEB = \"data_ingestion/bhuvan_data/web_pages\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "directories = [ROOT_MOSDAC_PDF, ROOT_MOSDAC_WEB, ROOT_VEDAS_WEB, ROOT_BHUVAN_WEB]\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"üìÅ Directory ready: {directory}\")\n",
    "\n",
    "# Load documents from all platforms\n",
    "print(\"\\nüîÑ Loading documents from all platforms...\")\n",
    "\n",
    "mosdac_pdfs = load_pdf_folder(ROOT_MOSDAC_PDF, \"mosdac\")\n",
    "mosdac_txt = load_txt_folder(ROOT_MOSDAC_WEB, \"mosdac\")\n",
    "mosdac_html = load_html_folder(ROOT_MOSDAC_WEB, \"mosdac\")\n",
    "\n",
    "vedas_txt = load_txt_folder(ROOT_VEDAS_WEB, \"vedas\")\n",
    "vedas_html = load_html_folder(ROOT_VEDAS_WEB, \"vedas\")\n",
    "\n",
    "bhuvan_txt = load_txt_folder(ROOT_BHUVAN_WEB, \"bhuvan\")\n",
    "bhuvan_html = load_html_folder(ROOT_BHUVAN_WEB, \"bhuvan\")\n",
    "\n",
    "# Combine all documents\n",
    "documents_all = mosdac_pdfs + mosdac_txt + mosdac_html + vedas_txt + vedas_html + bhuvan_txt + bhuvan_html\n",
    "\n",
    "print(f\"\\nüìä Total documents loaded: {len(documents_all)}\")\n",
    "if documents_all:\n",
    "    print(\"üìã Sample metadata:\", documents_all[0].metadata)\n",
    "    \n",
    "    # Count by platform\n",
    "    platform_counts = {}\n",
    "    for doc in documents_all:\n",
    "        platform = doc.metadata.get('source_site', 'unknown')\n",
    "        platform_counts[platform] = platform_counts.get(platform, 0) + 1\n",
    "    \n",
    "    print(\"üìà Documents by platform:\")\n",
    "    for platform, count in platform_counts.items():\n",
    "        print(f\"   {platform.upper()}: {count} documents\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No documents found! Please add files to the data directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61149bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Splitting documents into chunks...\n",
      "üìä Total chunks created: 4596\n",
      "üìà Chunks by platform:\n",
      "   MOSDAC: 3956 chunks\n",
      "   VEDAS: 634 chunks\n",
      "   BHUVAN: 6 chunks\n",
      "\n",
      "üìã Sample chunk metadata: {'producer': 'Nitro PDF PrimoPDF', 'creator': 'PrimoPDF http://www.primopdf.com', 'creationdate': '2012-03-20T14:49:18-05:30', 'moddate': '2012-03-20T14:49:18-05:30', 'title': 'Microsoft Word - Analysed-Winds', 'author': 'admin', 'source': 'data_ingestion\\\\mosdac_data\\\\documents\\\\Analysed-Winds.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1', 'source_site': 'mosdac'}\n",
      "üìù Sample content preview: GLOBAL ANALYSED OCEAN SURFACE WIND PRODUCTS \n",
      " \n",
      " \n",
      "Description \n",
      "The analysed winds have been generated at 0.5 \n",
      "0√ó0.5 0 interval over the global oceans. For the generation of \n",
      "these analysed winds produc...\n"
     ]
    }
   ],
   "source": [
    "# Text splitting with optimized parameters\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "print(\"üîÑ Splitting documents into chunks...\")\n",
    "chunks_all = text_splitter.split_documents(documents_all)\n",
    "print(f\"üìä Total chunks created: {len(chunks_all)}\")\n",
    "\n",
    "# Analyze chunks by platform\n",
    "if chunks_all:\n",
    "    chunk_counts = {}\n",
    "    for chunk in chunks_all:\n",
    "        platform = chunk.metadata.get('source_site', 'unknown')\n",
    "        chunk_counts[platform] = chunk_counts.get(platform, 0) + 1\n",
    "    \n",
    "    print(\"üìà Chunks by platform:\")\n",
    "    for platform, count in chunk_counts.items():\n",
    "        print(f\"   {platform.upper()}: {count} chunks\")\n",
    "    \n",
    "    # Show sample chunk\n",
    "    first_chunk = chunks_all[0]\n",
    "    print(f\"\\nüìã Sample chunk metadata: {first_chunk.metadata}\")\n",
    "    print(f\"üìù Sample content preview: {first_chunk.page_content[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b73f14e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Setting up vector store...\n",
      "üóëÔ∏è Removing existing vector store...\n",
      "‚úÖ Old vector store removed\n",
      "üîÑ Creating new vector store...\n",
      "üìä Inserting 4596 chunks in batches of 64...\n",
      "‚úÖ Progress: 64/4596 chunks (1.4%)\n",
      "‚úÖ Progress: 128/4596 chunks (2.8%)\n",
      "‚úÖ Progress: 192/4596 chunks (4.2%)\n",
      "‚úÖ Progress: 256/4596 chunks (5.6%)\n",
      "‚úÖ Progress: 320/4596 chunks (7.0%)\n",
      "‚úÖ Progress: 384/4596 chunks (8.4%)\n",
      "‚úÖ Progress: 448/4596 chunks (9.7%)\n",
      "‚úÖ Progress: 512/4596 chunks (11.1%)\n",
      "‚úÖ Progress: 576/4596 chunks (12.5%)\n",
      "‚úÖ Progress: 640/4596 chunks (13.9%)\n",
      "‚úÖ Progress: 704/4596 chunks (15.3%)\n",
      "‚úÖ Progress: 768/4596 chunks (16.7%)\n",
      "‚úÖ Progress: 832/4596 chunks (18.1%)\n",
      "‚úÖ Progress: 896/4596 chunks (19.5%)\n",
      "‚úÖ Progress: 960/4596 chunks (20.9%)\n",
      "‚úÖ Progress: 1024/4596 chunks (22.3%)\n",
      "‚úÖ Progress: 1088/4596 chunks (23.7%)\n",
      "‚úÖ Progress: 1152/4596 chunks (25.1%)\n",
      "‚úÖ Progress: 1216/4596 chunks (26.5%)\n",
      "‚úÖ Progress: 1280/4596 chunks (27.9%)\n",
      "‚úÖ Progress: 1344/4596 chunks (29.2%)\n",
      "‚úÖ Progress: 1408/4596 chunks (30.6%)\n",
      "‚úÖ Progress: 1472/4596 chunks (32.0%)\n",
      "‚úÖ Progress: 1536/4596 chunks (33.4%)\n",
      "‚úÖ Progress: 1600/4596 chunks (34.8%)\n",
      "‚úÖ Progress: 1664/4596 chunks (36.2%)\n",
      "‚úÖ Progress: 1728/4596 chunks (37.6%)\n",
      "‚úÖ Progress: 1792/4596 chunks (39.0%)\n",
      "‚úÖ Progress: 1856/4596 chunks (40.4%)\n",
      "‚úÖ Progress: 1920/4596 chunks (41.8%)\n",
      "‚úÖ Progress: 1984/4596 chunks (43.2%)\n",
      "‚úÖ Progress: 2048/4596 chunks (44.6%)\n",
      "‚úÖ Progress: 2112/4596 chunks (46.0%)\n",
      "‚úÖ Progress: 2176/4596 chunks (47.3%)\n",
      "‚úÖ Progress: 2240/4596 chunks (48.7%)\n",
      "‚úÖ Progress: 2304/4596 chunks (50.1%)\n",
      "‚úÖ Progress: 2368/4596 chunks (51.5%)\n",
      "‚úÖ Progress: 2432/4596 chunks (52.9%)\n",
      "‚úÖ Progress: 2496/4596 chunks (54.3%)\n",
      "‚úÖ Progress: 2560/4596 chunks (55.7%)\n",
      "‚úÖ Progress: 2624/4596 chunks (57.1%)\n",
      "‚úÖ Progress: 2688/4596 chunks (58.5%)\n",
      "‚úÖ Progress: 2752/4596 chunks (59.9%)\n",
      "‚úÖ Progress: 2816/4596 chunks (61.3%)\n",
      "‚úÖ Progress: 2880/4596 chunks (62.7%)\n",
      "‚úÖ Progress: 2944/4596 chunks (64.1%)\n",
      "‚úÖ Progress: 3008/4596 chunks (65.4%)\n",
      "‚úÖ Progress: 3072/4596 chunks (66.8%)\n",
      "‚úÖ Progress: 3136/4596 chunks (68.2%)\n",
      "‚úÖ Progress: 3200/4596 chunks (69.6%)\n",
      "‚úÖ Progress: 3264/4596 chunks (71.0%)\n",
      "‚úÖ Progress: 3328/4596 chunks (72.4%)\n",
      "‚úÖ Progress: 3392/4596 chunks (73.8%)\n",
      "‚úÖ Progress: 3456/4596 chunks (75.2%)\n",
      "‚úÖ Progress: 3520/4596 chunks (76.6%)\n",
      "‚úÖ Progress: 3584/4596 chunks (78.0%)\n",
      "‚úÖ Progress: 3648/4596 chunks (79.4%)\n",
      "‚úÖ Progress: 3712/4596 chunks (80.8%)\n",
      "‚úÖ Progress: 3776/4596 chunks (82.2%)\n",
      "‚úÖ Progress: 3840/4596 chunks (83.6%)\n",
      "‚úÖ Progress: 3904/4596 chunks (84.9%)\n",
      "‚úÖ Progress: 3968/4596 chunks (86.3%)\n",
      "‚úÖ Progress: 4032/4596 chunks (87.7%)\n",
      "‚úÖ Progress: 4096/4596 chunks (89.1%)\n",
      "‚úÖ Progress: 4160/4596 chunks (90.5%)\n",
      "‚úÖ Progress: 4224/4596 chunks (91.9%)\n",
      "‚úÖ Progress: 4288/4596 chunks (93.3%)\n",
      "‚úÖ Progress: 4352/4596 chunks (94.7%)\n",
      "‚úÖ Progress: 4416/4596 chunks (96.1%)\n",
      "‚úÖ Progress: 4480/4596 chunks (97.5%)\n",
      "‚úÖ Progress: 4544/4596 chunks (98.9%)\n",
      "‚úÖ Progress: 4596/4596 chunks (100.0%)\n",
      "üéâ Vector store created successfully!\n",
      "üìä Final collection size: 4596\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings and vector store\n",
    "print(\"üîÑ Setting up vector store...\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Optional: start from a clean collection if you want to rebuild\n",
    "if os.path.exists(db_name):\n",
    "    print(\"üóëÔ∏è Removing existing vector store...\")\n",
    "    try:\n",
    "        old_store = Chroma(persist_directory=db_name, embedding_function=embeddings)\n",
    "        old_store.delete_collection()\n",
    "        print(\"‚úÖ Old vector store removed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not remove old store: {e}\")\n",
    "\n",
    "print(\"üîÑ Creating new vector store...\")\n",
    "vectorstore = Chroma(persist_directory=db_name, embedding_function=embeddings)\n",
    "\n",
    "# Batch insert with progress tracking\n",
    "if chunks_all:\n",
    "    BATCH_SIZE = 64\n",
    "    total_chunks = len(chunks_all)\n",
    "    \n",
    "    print(f\"üìä Inserting {total_chunks} chunks in batches of {BATCH_SIZE}...\")\n",
    "    \n",
    "    for i in range(0, total_chunks, BATCH_SIZE):\n",
    "        batch = chunks_all[i:i+BATCH_SIZE]\n",
    "        vectorstore.add_documents(batch)\n",
    "        \n",
    "        progress = min(i + BATCH_SIZE, total_chunks)\n",
    "        percentage = (progress / total_chunks) * 100\n",
    "        print(f\"‚úÖ Progress: {progress}/{total_chunks} chunks ({percentage:.1f}%)\")\n",
    "    \n",
    "    final_count = vectorstore._collection.count()\n",
    "    print(f\"üéâ Vector store created successfully!\")\n",
    "    print(f\"üìä Final collection size: {final_count}\")\n",
    "else:\n",
    "    print(\"‚ùå No chunks to insert into vector store!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ef09521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Setting up RAG chain...\n",
      "‚úÖ RAG chain setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM and retriever\n",
    "print(\"üîÑ Setting up RAG chain...\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# Enhanced prompt template\n",
    "rag_prompt_template = \"\"\"You are ASTROGEO AI, a specialized assistant for Indian space and earth observation data platforms.\n",
    "\n",
    "You have access to information from three major platforms:\n",
    "- MOSDAC: Meteorological & Oceanographic Satellite Data Archival Centre\n",
    "- VEDAS: Visualization of Earth observation Data and Archival System  \n",
    "- BHUVAN: Indian Geo-platform for visualization and analysis\n",
    "\n",
    "Instructions:\n",
    "1. Answer questions based on the provided context documents\n",
    "2. If information is available in the documents, provide detailed, comprehensive responses\n",
    "3. Always mention which platform(s) the information comes from (MOSDAC, VEDAS, or BHUVAN)\n",
    "4. If documents don't contain the answer, use general knowledge but clearly state this\n",
    "5. Be helpful, accurate, and technical when appropriate\n",
    "6. For data access questions, provide specific steps and requirements\n",
    "\n",
    "Context from documents:\n",
    "{context}\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Response:\"\"\"\n",
    "\n",
    "RAG_PROMPT = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "# Create the conversational RAG chain\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": RAG_PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG chain setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "484ca215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Smart bot function ready!\n"
     ]
    }
   ],
   "source": [
    "def is_relevant(question, docs):\n",
    "    \"\"\"Check if retrieved documents are relevant to the question\"\"\"\n",
    "    if not docs:\n",
    "        return False\n",
    "    \n",
    "    # Take the first document for relevance check\n",
    "    doc_content = docs[0].page_content[:1500] if docs else \"\"\n",
    "    \n",
    "    relevance_prompt = f\"\"\"Analyze if the following document content is relevant to answer the user's question.\n",
    "    Answer only \"Yes\" or \"No\".\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Document Content: {doc_content}\n",
    "    \n",
    "    Relevance Assessment:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        check = llm.invoke(relevance_prompt)\n",
    "        return \"Yes\" in check.content\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Relevance check error: {e}\")\n",
    "        return True  # Default to using RAG if check fails\n",
    "\n",
    "# Fallback prompt for general knowledge responses\n",
    "fallback_prompt_template = \"\"\"You are ASTROGEO AI, a helpful assistant specializing in Indian space and earth observation platforms (MOSDAC, VEDAS, BHUVAN).\n",
    "\n",
    "The user's question doesn't seem to be directly related to the documents in your knowledge base, so please answer using your general knowledge while staying within your area of expertise.\n",
    "\n",
    "If the question is about:\n",
    "- Satellite data, remote sensing, or earth observation\n",
    "- Indian space programs (ISRO)\n",
    "- Weather and climate data\n",
    "- GIS and mapping\n",
    "- Data access and processing\n",
    "\n",
    "Please provide a helpful response. If it's completely outside your domain, politely redirect to your specializations.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Response:\"\"\"\n",
    "\n",
    "FALLBACK_PROMPT = PromptTemplate.from_template(fallback_prompt_template)\n",
    "\n",
    "def smart_bot(message, history):\n",
    "    \"\"\"Main chatbot function with smart routing\"\"\"\n",
    "    try:\n",
    "        # Retrieve relevant documents\n",
    "        docs = retriever.get_relevant_documents(message)\n",
    "        \n",
    "        # Check relevance and route accordingly\n",
    "        if docs and is_relevant(message, docs):\n",
    "            # Use RAG chain for document-based response\n",
    "            result = rag_chain.invoke({\"question\": message})\n",
    "            \n",
    "            # Add source information\n",
    "            sources = set()\n",
    "            if hasattr(result, 'source_documents') and result['source_documents']:\n",
    "                for doc in result['source_documents']:\n",
    "                    source_site = doc.metadata.get('source_site', 'unknown')\n",
    "                    sources.add(source_site.upper())\n",
    "            \n",
    "            response = result[\"answer\"]\n",
    "            if sources:\n",
    "                response += f\"\\n\\n*Sources: {', '.join(sources)}*\"\n",
    "            \n",
    "            return response\n",
    "        else:\n",
    "            # Use fallback for general knowledge\n",
    "            chain = FALLBACK_PROMPT | llm\n",
    "            result = chain.invoke({\"question\": message})\n",
    "            return result.content + \"\\n\\n*Note: This response is based on general knowledge as no relevant documents were found in the knowledge base.*\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Sorry, I encountered an error: {str(e)}. Please try rephrasing your question.\"\n",
    "\n",
    "print(\"‚úÖ Smart bot function ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3563fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching ASTROGEO AI Chat Interface...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Launch error: Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and launch the Gradio interface\n",
    "print(\"üöÄ Launching ASTROGEO AI Chat Interface...\")\n",
    "\n",
    "# Custom CSS for better appearance\n",
    "custom_css = \"\"\"\n",
    ".gradio-container {\n",
    "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Create the chat interface\n",
    "interface = gr.ChatInterface(\n",
    "    fn=smart_bot,\n",
    "    title=\"üõ∞Ô∏è ASTROGEO AI ‚Äî Multi-Platform Earth Observation Assistant\",\n",
    "    description=\"\"\"\n",
    "    **Powered by MOSDAC + VEDAS + BHUVAN Knowledge Base**\n",
    "    \n",
    "    Ask me about:\n",
    "    ‚Ä¢ MOSDAC satellite data and services\n",
    "    ‚Ä¢ VEDAS earth observation and visualization\n",
    "    ‚Ä¢ BHUVAN geospatial data and mapping\n",
    "    ‚Ä¢ Data access procedures and formats\n",
    "    ‚Ä¢ Indian space and remote sensing programs\n",
    "    \"\"\",\n",
    "    theme=\"soft\",\n",
    "    css=custom_css,\n",
    "    examples=[\n",
    "        \"What types of data are available in MOSDAC?\",\n",
    "        \"How do I access satellite imagery from VEDAS?\",\n",
    "        \"What mapping services does BHUVAN provide?\",\n",
    "        \"How can I download INSAT-3D data?\",\n",
    "        \"What are the data formats supported by these platforms?\",\n",
    "        \"Tell me about Indian earth observation satellites\"\n",
    "    ],\n",
    "    cache_examples=False,\n",
    "    analytics_enabled=False\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "try:\n",
    "    interface.launch(\n",
    "        share=True,  # Creates public link\n",
    "        server_name=\"0.0.0.0\",  # Makes it accessible on network\n",
    "        server_port=7860,  # Default Gradio port\n",
    "        show_error=True\n",
    "    )\n",
    "    print(\"‚úÖ Interface launched successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Launch error: {e}\")\n",
    "    # Fallback launch without share\n",
    "    interface.launch(show_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0b7b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ ASTROGEO AI is ready!\n",
      "üìä System Statistics:\n",
      "   ‚Ä¢ Total documents: 1724\n",
      "   ‚Ä¢ Total chunks: 4596\n",
      "   ‚Ä¢ Vector store size: 4596\n",
      "   ‚Ä¢ Model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Test the system with sample queries\n",
    "def test_system():\n",
    "    \"\"\"Test the chatbot with sample queries\"\"\"\n",
    "    test_queries = [\n",
    "        \"What is MOSDAC?\",\n",
    "        \"How do I access VEDAS data?\",\n",
    "        \"What services does BHUVAN provide?\",\n",
    "        \"Tell me about INSAT satellites\",\n",
    "        \"What is the weather like today?\"  # This should trigger fallback\n",
    "    ]\n",
    "    \n",
    "    print(\"üß™ Testing the system with sample queries...\")\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Test {i}: {query}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        try:\n",
    "            response = smart_bot(query, [])\n",
    "            print(f\"Response: {response[:300]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Uncomment the line below to run tests\n",
    "# test_system()\n",
    "\n",
    "print(\"\\nüéâ ASTROGEO AI is ready!\")\n",
    "print(\"üìä System Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total documents: {len(documents_all)}\")\n",
    "print(f\"   ‚Ä¢ Total chunks: {len(chunks_all)}\")\n",
    "print(f\"   ‚Ä¢ Vector store size: {vectorstore._collection.count()}\")\n",
    "print(f\"   ‚Ä¢ Model: {MODEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c4818ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Additional dependencies installed!\n",
      "‚úÖ HF_TOKEN loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Install additional packages for image generation\n",
    "!pip install huggingface_hub --upgrade --quiet\n",
    "!pip install Pillow --upgrade --quiet\n",
    "\n",
    "print(\"‚úÖ Additional dependencies installed!\")\n",
    "# Add HF_TOKEN for image generation\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-hugging-face-token-here')\n",
    "\n",
    "# Verify HF token\n",
    "if not os.getenv('HF_TOKEN'):\n",
    "    print(\"‚ö†Ô∏è Warning: HF_TOKEN not found!\")\n",
    "else:\n",
    "    print(\"‚úÖ HF_TOKEN loaded successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d9202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initializing ASTROGEO Image Generator...\n",
      "‚úÖ ASTROGEO Image Generator ready!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from IPython.display import Image, display\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "\n",
    "class SimpleImageGenerator:\n",
    "    def __init__(self, hf_token):\n",
    "        self.client = InferenceClient(provider=\"fal-ai\", api_key=hf_token)\n",
    "        \n",
    "    def generate_image(self, prompt):\n",
    "        try:\n",
    "            # Generate image with FLUX model\n",
    "            response = self.client.text_to_image(\n",
    "                prompt=f\"High-resolution astronomical visualization of {prompt}, cosmic photography, space telescope quality, detailed celestial objects\",\n",
    "                model=\"black-forest-labs/FLUX.1-dev\"\n",
    "            )\n",
    "            return response, \"‚úÖ Generated successfully\"\n",
    "        except Exception as e:\n",
    "            return None, f\"‚ùå Generation failed: {str(e)}\"\n",
    "\n",
    "# Initialize image generator\n",
    "if os.getenv('HF_TOKEN'):\n",
    "    image_gen = SimpleImageGenerator(os.getenv('HF_TOKEN'))\n",
    "    print(\"‚úÖ Image generator ready!\")\n",
    "else:\n",
    "    image_gen = None\n",
    "    print(\"‚ùå Image generator not available - missing HF_TOKEN\")\n",
    "\n",
    "\n",
    "class ASTROGEOImageGenerator:\n",
    "    \"\"\"Enhanced image generator for ASTROGEO AI with dual specialty support\"\"\"\n",
    "    def create_image_enabled_interface():\n",
    "    \"\"\"Create interface with working image generation\"\"\"\n",
    "    \n",
    "    custom_css = \"\"\"\n",
    "    .gradio-container { max-width: 1400px !important; margin: 0 auto !important; }\n",
    "    .astronomy-mode { background: linear-gradient(45deg, #1a1a3e, #4a90e2); color: white; padding: 15px; border-radius: 10px; text-align: center; }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(css=custom_css, title=\"üõ∞Ô∏è ASTROGEO AI + Image Gen\") as interface:\n",
    "        \n",
    "        gr.HTML(\"\"\"\n",
    "        <div style='text-align: center; padding: 25px; background: linear-gradient(45deg, #1e3c72, #27ae60); border-radius: 15px; margin-bottom: 20px;'>\n",
    "            <h1 style='color: white; font-size: 2.5em;'>üõ∞Ô∏è ASTROGEO AI + IMAGE GENERATION</h1>\n",
    "            <p style='color: white; font-size: 1.2em;'>Text + Image Generation Enabled</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                chatbot = gr.Chatbot(label=\"üõ∞Ô∏è ASTROGEO AI\", height=500)\n",
    "                \n",
    "                with gr.Row():\n",
    "                    msg = gr.Textbox(\n",
    "                        placeholder=\"Ask questions or request images (e.g., 'generate image of black hole')\",\n",
    "                        lines=2, scale=4\n",
    "                    )\n",
    "                    send_btn = gr.Button(\"üöÄ Send\", variant=\"primary\")\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                image_output = gr.Image(label=\"Generated Image\", visible=False, height=400)\n",
    "                status_output = gr.HTML(\"Ready for questions...\")\n",
    "        \n",
    "        def respond_with_images(message, history):\n",
    "            if not message.strip():\n",
    "                return history, \"\", None, gr.update(visible=False), \"Please enter a message\"\n",
    "            \n",
    "            try:\n",
    "                # Get text response from your existing smart_bot\n",
    "                text_response = smart_bot(message, history)\n",
    "                \n",
    "                # Check if image generation is requested\n",
    "                image_triggers = [\"generate\", \"image\", \"picture\", \"show me\", \"visualize\", \"create\"]\n",
    "                needs_image = any(trigger in message.lower() for trigger in image_triggers)\n",
    "                \n",
    "                if needs_image and image_gen:\n",
    "                    # Generate image\n",
    "                    generated_image, image_status = image_gen.generate_image(message)\n",
    "                    \n",
    "                    if generated_image:\n",
    "                        enhanced_response = f\"{text_response}\\n\\nüñºÔ∏è **{image_status}**\"\n",
    "                        history.append((message, enhanced_response))\n",
    "                        \n",
    "                        return (\n",
    "                            history, \n",
    "                            \"\", \n",
    "                            generated_image, \n",
    "                            gr.update(visible=True),\n",
    "                            \"<div class='astronomy-mode'><h3>üåå IMAGE GENERATED!</h3></div>\"\n",
    "                        )\n",
    "                    else:\n",
    "                        enhanced_response = f\"{text_response}\\n\\n‚ùå **{image_status}**\"\n",
    "                        history.append((message, enhanced_response))\n",
    "                        return history, \"\", None, gr.update(visible=False), image_status\n",
    "                else:\n",
    "                    # Text-only response\n",
    "                    history.append((message, text_response))\n",
    "                    return history, \"\", None, gr.update(visible=False), \"Text response provided\"\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = f\"‚ùå Error: {str(e)}\"\n",
    "                history.append((message, error_msg))\n",
    "                return history, \"\", None, gr.update(visible=False), f\"Error: {str(e)}\"\n",
    "        \n",
    "        # Connect events\n",
    "        send_btn.click(\n",
    "            respond_with_images,\n",
    "            [msg, chatbot],\n",
    "            [chatbot, msg, image_output, image_output, status_output]\n",
    "        )\n",
    "        \n",
    "        msg.submit(\n",
    "            respond_with_images,\n",
    "            [msg, chatbot],\n",
    "            [chatbot, msg, image_output, image_output, status_output]\n",
    "        )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create the enhanced interface\n",
    "working_interface = create_image_enabled_interface()\n",
    "print(\"‚úÖ Image-enabled interface created!\")\n",
    "\n",
    "    \n",
    "    def __init__(self, hf_token):\n",
    "        self.client = InferenceClient(\n",
    "            provider=\"fal-ai\",\n",
    "            api_key=hf_token\n",
    "        )\n",
    "        \n",
    "        # Available models for different purposes\n",
    "        self.models = {\n",
    "            \"flux\": \"black-forest-labs/FLUX.1-dev\",  # Best quality\n",
    "            \"stable_diffusion\": \"stabilityai/stable-diffusion-xl-base-1.0\",  # Reliable\n",
    "            \"recraft\": \"fal-ai/recraft-v3\"  # Technical diagrams\n",
    "        }\n",
    "        \n",
    "        # Keywords for smart classification\n",
    "        self.astronomy_keywords = [\n",
    "            \"star\", \"galaxy\", \"nebula\", \"planet\", \"cosmos\", \"universe\", \"telescope\", \n",
    "            \"constellation\", \"black hole\", \"solar system\", \"asteroid\", \"comet\",\n",
    "            \"space\", \"celestial\", \"astronomical\", \"cosmic\", \"lunar\", \"mars\", \"jupiter\"\n",
    "        ]\n",
    "        \n",
    "        self.geospatial_keywords = [\n",
    "            \"satellite\", \"earth\", \"landsat\", \"sentinel\", \"modis\", \"radar\", \"lidar\",\n",
    "            \"remote sensing\", \"gis\", \"mapping\", \"terrain\", \"land use\", \"forest\",\n",
    "            \"agriculture\", \"urban\", \"mosdac\", \"vedas\", \"bhuvan\", \"insat\", \"weather\"\n",
    "        ]\n",
    "    \n",
    "    def classify_image_type(self, prompt):\n",
    "        \"\"\"Classify if prompt is astronomy or geospatial focused\"\"\"\n",
    "        prompt_lower = prompt.lower()\n",
    "        \n",
    "        astro_score = sum(1 for keyword in self.astronomy_keywords if keyword in prompt_lower)\n",
    "        geo_score = sum(1 for keyword in self.geospatial_keywords if keyword in prompt_lower)\n",
    "        \n",
    "        if astro_score > geo_score:\n",
    "            return \"astronomy\"\n",
    "        elif geo_score > astro_score:\n",
    "            return \"geospatial\"\n",
    "        else:\n",
    "            return \"geospatial\"  # Default to geospatial for earth observation focus\n",
    "    \n",
    "    def enhance_prompt(self, prompt, specialty=\"auto\"):\n",
    "        \"\"\"Enhance prompt based on specialty\"\"\"\n",
    "        if specialty == \"auto\":\n",
    "            specialty = self.classify_image_type(prompt)\n",
    "        \n",
    "        if specialty == \"astronomy\":\n",
    "            enhanced = f\"High-resolution astronomical image of {prompt}, deep space photography, cosmic details, professional space telescope quality, detailed celestial objects, 4K resolution\"\n",
    "        else:  # geospatial\n",
    "            enhanced = f\"High-resolution satellite imagery of {prompt}, earth observation style, remote sensing visualization, technical accuracy, geographic detail, professional satellite photography\"\n",
    "        \n",
    "        return enhanced, specialty\n",
    "    \n",
    "    def generate_image(self, prompt, model=\"flux\", enhance=True):\n",
    "        \"\"\"Generate image with enhanced prompts and error handling\"\"\"\n",
    "        try:\n",
    "            # Enhance prompt if requested\n",
    "            if enhance:\n",
    "                enhanced_prompt, detected_specialty = self.enhance_prompt(prompt)\n",
    "                specialty_info = f\"üåå ASTRONOMY\" if detected_specialty == \"astronomy\" else \"üõ∞Ô∏è GEOSPATIAL\"\n",
    "            else:\n",
    "                enhanced_prompt = prompt\n",
    "                specialty_info = \"üé® GENERAL\"\n",
    "            \n",
    "            # Select model\n",
    "            selected_model = self.models.get(model, self.models[\"flux\"])\n",
    "            \n",
    "            # Generate image\n",
    "            response = self.client.text_to_image(\n",
    "                prompt=enhanced_prompt,\n",
    "                model=selected_model\n",
    "            )\n",
    "            \n",
    "            status = f\"‚úÖ Generated | {specialty_info} | Model: {model.upper()}\"\n",
    "            return response, status, detected_specialty if enhance else \"general\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback to stable diffusion\n",
    "            try:\n",
    "                response = self.client.text_to_image(\n",
    "                    prompt=prompt,\n",
    "                    model=self.models[\"stable_diffusion\"]\n",
    "                )\n",
    "                return response, f\"‚úÖ Generated with Stable Diffusion (fallback)\", \"fallback\"\n",
    "            except Exception as fallback_error:\n",
    "                return None, f\"‚ùå Generation failed: {str(fallback_error)}\", \"error\"\n",
    "\n",
    "# Initialize image generator\n",
    "print(\"üîÑ Initializing ASTROGEO Image Generator...\")\n",
    "image_generator = ASTROGEOImageGenerator(os.getenv('OPENAI_API_KEY'))  # Using your existing env var\n",
    "print(\"‚úÖ ASTROGEO Image Generator ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba91c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2369a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced ASTROGEO Bot with image generation ready!\n"
     ]
    }
   ],
   "source": [
    "class EnhancedASTROGEOBot:\n",
    "    \"\"\"Enhanced ASTROGEO bot with integrated image generation\"\"\"\n",
    "    \n",
    "    def __init__(self, existing_smart_bot, image_gen):\n",
    "        self.smart_bot = existing_smart_bot  # Your existing smart_bot function\n",
    "        self.image_gen = image_gen\n",
    "        \n",
    "    def process_message_with_images(self, message, history):\n",
    "        \"\"\"Process message and determine if image generation is needed\"\"\"\n",
    "        try:\n",
    "            # Image generation triggers\n",
    "            image_triggers = [\n",
    "                \"image\", \"picture\", \"photo\", \"visualize\", \"visualization\", \"show me\", \n",
    "                \"generate\", \"create\", \"draw\", \"display\", \"diagram\", \"chart\", \"map\"\n",
    "            ]\n",
    "            \n",
    "            # Check if user wants an image\n",
    "            needs_image = any(trigger in message.lower() for trigger in image_triggers)\n",
    "            \n",
    "            # Get text response from your existing smart_bot\n",
    "            text_response = self.smart_bot(message, history)\n",
    "            \n",
    "            if needs_image:\n",
    "                # Generate image\n",
    "                image, status, specialty = self.image_gen.generate_image(\n",
    "                    prompt=message,\n",
    "                    model=\"flux\",\n",
    "                    enhance=True\n",
    "                )\n",
    "                \n",
    "                # Enhanced text response\n",
    "                enhanced_response = f\"{text_response}\\n\\nüì∏ **{status}**\"\n",
    "                \n",
    "                return enhanced_response, image\n",
    "            else:\n",
    "                return text_response, None\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error processing message: {str(e)}\", None\n",
    "\n",
    "# Initialize enhanced bot using your existing smart_bot function\n",
    "enhanced_astrogeo_bot = EnhancedASTROGEOBot(smart_bot, image_generator)\n",
    "print(\"‚úÖ Enhanced ASTROGEO Bot with image generation ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8736055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_636\\826338290.py:63: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_636\\826338290.py:63: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced Gradio interface created!\n"
     ]
    }
   ],
   "source": [
    "def create_enhanced_gradio_interface():\n",
    "    \"\"\"Create enhanced Gradio interface with image generation support\"\"\"\n",
    "    \n",
    "    # Custom CSS for better appearance\n",
    "    custom_css = \"\"\"\n",
    "    .gradio-container {\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;\n",
    "        max-width: 1200px !important;\n",
    "        margin: 0 auto !important;\n",
    "    }\n",
    "    .image-container {\n",
    "        border: 2px solid #e1e1e1;\n",
    "        border-radius: 10px;\n",
    "        padding: 10px;\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    .specialty-astronomy {\n",
    "        background: linear-gradient(45deg, #1a1a3e, #4a90e2);\n",
    "        color: white;\n",
    "        padding: 10px;\n",
    "        border-radius: 8px;\n",
    "        margin: 5px;\n",
    "    }\n",
    "    .specialty-geospatial {\n",
    "        background: linear-gradient(45deg, #1e4d2b, #27ae60);\n",
    "        color: white;\n",
    "        padding: 10px;\n",
    "        border-radius: 8px;\n",
    "        margin: 5px;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(css=custom_css, theme=\"soft\", title=\"üõ∞Ô∏è ASTROGEO AI Enhanced\") as interface:\n",
    "        \n",
    "        # Enhanced header\n",
    "        gr.HTML(\"\"\"\n",
    "        <div style='text-align: center; padding: 25px; background: linear-gradient(45deg, #1e3c72, #2a5298, #27ae60); border-radius: 15px; margin-bottom: 20px;'>\n",
    "            <h1 style='color: white; margin-bottom: 10px; font-size: 2.5em;'>üõ∞Ô∏è ASTROGEO AI ENHANCED</h1>\n",
    "            <p style='color: #e8f4ff; font-size: 1.2em; margin-bottom: 15px;'><strong>Multi-Platform Earth Observation + Image Generation</strong></p>\n",
    "            <div style='display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;'>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 12px; border-radius: 8px; min-width: 150px;'>\n",
    "                    <div style='font-size: 1.5em; margin-bottom: 5px;'>üåå</div>\n",
    "                    <div style='font-weight: bold;'>ASTRONOMY</div>\n",
    "                    <div style='font-size: 0.9em;'>Deep Space ‚Ä¢ Telescopes</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 12px; border-radius: 8px; min-width: 150px;'>\n",
    "                    <div style='font-size: 1.5em; margin-bottom: 5px;'>üõ∞Ô∏è</div>\n",
    "                    <div style='font-weight: bold;'>GEOSPATIAL</div>\n",
    "                    <div style='font-size: 0.9em;'>Earth Observation ‚Ä¢ GIS</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 12px; border-radius: 8px; min-width: 150px;'>\n",
    "                    <div style='font-size: 1.5em; margin-bottom: 5px;'>üé®</div>\n",
    "                    <div style='font-weight: bold;'>IMAGE AI</div>\n",
    "                    <div style='font-size: 0.9em;'>Advanced Visualization</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Main chat interface\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                chatbot = gr.Chatbot(\n",
    "                    label=\"ASTROGEO AI Assistant\",\n",
    "                    height=500,\n",
    "                    bubble_full_width=False,\n",
    "                    show_label=True\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    msg = gr.Textbox(\n",
    "                        label=\"Your Message\",\n",
    "                        placeholder=\"Ask about MOSDAC, VEDAS, BHUVAN data or request visualizations...\",\n",
    "                        lines=3,\n",
    "                        scale=4,\n",
    "                        show_label=False\n",
    "                    )\n",
    "                    submit_btn = gr.Button(\"üöÄ Send\", variant=\"primary\", scale=1, size=\"lg\")\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                # Image output area\n",
    "                image_output = gr.Image(\n",
    "                    label=\"Generated Visualization\",\n",
    "                    height=400,\n",
    "                    visible=False,\n",
    "                    show_label=True,\n",
    "                    container=True\n",
    "                )\n",
    "                \n",
    "                # Status display\n",
    "                status_display = gr.HTML(\n",
    "                    value=\"<div style='text-align: center; padding: 20px; color: #666;'>üí≠ Ready for your questions...</div>\",\n",
    "                    visible=True\n",
    "                )\n",
    "        \n",
    "        # Enhanced examples section\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.HTML(\"<h3 style='color: #4a90e2; text-align: center;'>üåå ASTRONOMY EXAMPLES</h3>\")\n",
    "                gr.Examples(\n",
    "                    examples=[\n",
    "                        \"Show me an image of the Andromeda Galaxy\",\n",
    "                        \"What are the different types of nebulae? Show me one.\",\n",
    "                        \"Create a visualization of Jupiter's moons\",\n",
    "                        \"Generate an image of the James Webb Space Telescope\",\n",
    "                        \"Visualize a black hole with accretion disk\"\n",
    "                    ],\n",
    "                    inputs=msg,\n",
    "                    label=\"Astronomy Examples\"\n",
    "                )\n",
    "            \n",
    "            with gr.Column():\n",
    "                gr.HTML(\"<h3 style='color: #27ae60; text-align: center;'>üõ∞Ô∏è GEOSPATIAL EXAMPLES</h3>\")\n",
    "                gr.Examples(\n",
    "                    examples=[\n",
    "                        \"Show me MOSDAC satellite data visualization\",\n",
    "                        \"Create an image of forest monitoring from VEDAS\",\n",
    "                        \"Generate BHUVAN mapping interface visualization\",\n",
    "                        \"Show me INSAT-3D weather satellite imagery\",\n",
    "                        \"Visualize Landsat agricultural monitoring\"\n",
    "                    ],\n",
    "                    inputs=msg,\n",
    "                    label=\"Geospatial Examples\"\n",
    "                )\n",
    "        \n",
    "        # Settings section\n",
    "        with gr.Accordion(\"‚öôÔ∏è Advanced Settings\", open=False):\n",
    "            with gr.Row():\n",
    "                model_choice = gr.Dropdown(\n",
    "                    choices=[\"flux\", \"stable_diffusion\", \"recraft\"],\n",
    "                    value=\"flux\",\n",
    "                    label=\"Image Generation Model\",\n",
    "                    info=\"FLUX: Best quality | Stable Diffusion: Most reliable | Recraft: Technical diagrams\"\n",
    "                )\n",
    "                enhance_prompts = gr.Checkbox(\n",
    "                    value=True,\n",
    "                    label=\"Enhanced Prompts\",\n",
    "                    info=\"Automatically optimize prompts for better results\"\n",
    "                )\n",
    "        \n",
    "        # Chat functionality with image support\n",
    "        def respond_with_images(message, history, model, enhance):\n",
    "            try:\n",
    "                # Update image generator settings\n",
    "                enhanced_astrogeo_bot.image_gen.current_model = model\n",
    "                \n",
    "                # Process message\n",
    "                text_response, generated_image = enhanced_astrogeo_bot.process_message_with_images(message, history)\n",
    "                \n",
    "                # Update chat history\n",
    "                history.append((message, text_response))\n",
    "                \n",
    "                # Update status and image display\n",
    "                if generated_image:\n",
    "                    # Determine specialty for status display\n",
    "                    specialty = enhanced_astrogeo_bot.image_gen.classify_image_type(message)\n",
    "                    \n",
    "                    if specialty == \"astronomy\":\n",
    "                        status_html = \"\"\"\n",
    "                        <div class='specialty-astronomy' style='text-align: center;'>\n",
    "                            <h3>üåå ASTRONOMY MODE ACTIVATED</h3>\n",
    "                            <p>Generated cosmic visualization with astronomical accuracy</p>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                    else:\n",
    "                        status_html = \"\"\"\n",
    "                        <div class='specialty-geospatial' style='text-align: center;'>\n",
    "                            <h3>üõ∞Ô∏è GEOSPATIAL MODE ACTIVATED</h3>\n",
    "                            <p>Generated Earth observation visualization</p>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                    \n",
    "                    return (\n",
    "                        history, \n",
    "                        \"\", \n",
    "                        generated_image, \n",
    "                        gr.update(visible=True), \n",
    "                        status_html\n",
    "                    )\n",
    "                else:\n",
    "                    # Text-only response\n",
    "                    status_html = \"<div style='text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px;'><h4>üí¨ Text Response Generated</h4><p>No image generation requested</p></div>\"\n",
    "                    \n",
    "                    return (\n",
    "                        history, \n",
    "                        \"\", \n",
    "                        None, \n",
    "                        gr.update(visible=False), \n",
    "                        status_html\n",
    "                    )\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = f\"‚ùå Error: {str(e)}\"\n",
    "                history.append((message, error_msg))\n",
    "                error_html = f\"<div style='color: red; text-align: center; padding: 10px;'><strong>Error:</strong> {str(e)}</div>\"\n",
    "                \n",
    "                return (\n",
    "                    history, \n",
    "                    \"\", \n",
    "                    None, \n",
    "                    gr.update(visible=False), \n",
    "                    error_html\n",
    "                )\n",
    "        \n",
    "        # Event handlers\n",
    "                # Event handlers\n",
    "        submit_btn.click(\n",
    "            respond_with_images,\n",
    "            inputs=[msg, chatbot, model_choice, enhance_prompts],\n",
    "            outputs=[chatbot, msg, image_output, image_output, status_display],\n",
    "            queue=True\n",
    "        )\n",
    "        \n",
    "        msg.submit(\n",
    "            respond_with_images,\n",
    "            inputs=[msg, chatbot, model_choice, enhance_prompts],\n",
    "            outputs=[chatbot, msg, image_output, image_output, status_display],\n",
    "            queue=True\n",
    "        )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and store the enhanced interface\n",
    "enhanced_interface = create_enhanced_gradio_interface()\n",
    "print(\"‚úÖ Enhanced Gradio interface created!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a646bf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initializing ASTROGEO Image Generator with fal.ai compatible models...\n",
      "‚úÖ ASTROGEO Image Generator ready with working models!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from IPython.display import Image, display\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "class ASTROGEOImageGenerator:\n",
    "    \"\"\"Enhanced image generator with fal.ai compatible models\"\"\"\n",
    "    \n",
    "    def __init__(self, hf_token):\n",
    "        self.client = InferenceClient(\n",
    "            provider=\"fal-ai\",\n",
    "            api_key=hf_token\n",
    "        )\n",
    "        \n",
    "        # ‚úÖ FAL.AI COMPATIBLE MODELS ONLY\n",
    "        self.models = {\n",
    "            \"flux\": \"black-forest-labs/FLUX.1-dev\",     # ‚úÖ Works with fal.ai\n",
    "            \"flux_schnell\": \"black-forest-labs/FLUX.1-schnell\",  # ‚úÖ Faster FLUX\n",
    "            \"recraft\": \"recraft-ai/recraft-v3\",         # ‚úÖ Technical diagrams\n",
    "            \"aura\": \"fal-ai/aura-flow\",                 # ‚úÖ Alternative model\n",
    "        }\n",
    "        \n",
    "        # Keywords for smart classification\n",
    "        self.astronomy_keywords = [\n",
    "            \"star\", \"galaxy\", \"nebula\", \"planet\", \"cosmos\", \"universe\", \"telescope\", \n",
    "            \"constellation\", \"black hole\", \"solar system\", \"asteroid\", \"comet\",\n",
    "            \"space\", \"celestial\", \"astronomical\", \"cosmic\", \"lunar\", \"mars\", \"jupiter\"\n",
    "        ]\n",
    "        \n",
    "        self.geospatial_keywords = [\n",
    "            \"satellite\", \"earth\", \"landsat\", \"sentinel\", \"modis\", \"radar\", \"lidar\",\n",
    "            \"remote sensing\", \"gis\", \"mapping\", \"terrain\", \"land use\", \"forest\",\n",
    "            \"agriculture\", \"urban\", \"mosdac\", \"vedas\", \"bhuvan\", \"insat\", \"weather\"\n",
    "        ]\n",
    "    \n",
    "    def classify_image_type(self, prompt):\n",
    "        \"\"\"Classify if prompt is astronomy or geospatial focused\"\"\"\n",
    "        prompt_lower = prompt.lower()\n",
    "        \n",
    "        astro_score = sum(1 for keyword in self.astronomy_keywords if keyword in prompt_lower)\n",
    "        geo_score = sum(1 for keyword in self.geospatial_keywords if keyword in prompt_lower)\n",
    "        \n",
    "        if astro_score > geo_score:\n",
    "            return \"astronomy\"\n",
    "        elif geo_score > astro_score:\n",
    "            return \"geospatial\"\n",
    "        else:\n",
    "            return \"geospatial\"  # Default to geospatial for earth observation focus\n",
    "    \n",
    "    def enhance_prompt(self, prompt, specialty=\"auto\"):\n",
    "        \"\"\"Enhance prompt based on specialty\"\"\"\n",
    "        if specialty == \"auto\":\n",
    "            specialty = self.classify_image_type(prompt)\n",
    "        \n",
    "        if specialty == \"astronomy\":\n",
    "            enhanced = f\"High-resolution astronomical photograph of {prompt}, deep space imagery, cosmic details, professional space telescope quality, detailed celestial objects, stunning cosmic colors, 4K resolution\"\n",
    "        else:  # geospatial\n",
    "            enhanced = f\"High-resolution satellite imagery of {prompt}, earth observation photography, remote sensing visualization, technical accuracy, geographic detail, professional satellite photography, clear atmospheric view\"\n",
    "        \n",
    "        return enhanced, specialty\n",
    "    \n",
    "    def generate_image(self, prompt, model=\"flux\", enhance=True):\n",
    "        \"\"\"Generate image with fal.ai compatible models\"\"\"\n",
    "        try:\n",
    "            # Enhance prompt if requested\n",
    "            if enhance:\n",
    "                enhanced_prompt, detected_specialty = self.enhance_prompt(prompt)\n",
    "                specialty_info = f\"üåå ASTRONOMY\" if detected_specialty == \"astronomy\" else \"üõ∞Ô∏è GEOSPATIAL\"\n",
    "            else:\n",
    "                enhanced_prompt = prompt\n",
    "                specialty_info = \"üé® GENERAL\"\n",
    "            \n",
    "            # Select working model\n",
    "            selected_model = self.models.get(model, self.models[\"flux\"])\n",
    "            \n",
    "            # Generate image\n",
    "            response = self.client.text_to_image(\n",
    "                prompt=enhanced_prompt,\n",
    "                model=selected_model\n",
    "            )\n",
    "            \n",
    "            status = f\"‚úÖ Generated | {specialty_info} | Model: {model.upper()}\"\n",
    "            return response, status, detected_specialty if enhance else \"general\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Try different models in order\n",
    "            fallback_models = [\"flux_schnell\", \"aura\", \"recraft\"]\n",
    "            \n",
    "            for fallback_model in fallback_models:\n",
    "                if fallback_model != model:  # Don't retry the same model\n",
    "                    try:\n",
    "                        response = self.client.text_to_image(\n",
    "                            prompt=enhanced_prompt if enhance else prompt,\n",
    "                            model=self.models[fallback_model]\n",
    "                        )\n",
    "                        return response, f\"‚úÖ Generated with {fallback_model.upper()} (fallback)\", \"fallback\"\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            # If all models fail\n",
    "            return None, f\"‚ùå All models failed. Error: {str(e)}\", \"error\"\n",
    "\n",
    "# Initialize image generator with corrected models\n",
    "print(\"üîÑ Initializing ASTROGEO Image Generator with fal.ai compatible models...\")\n",
    "image_generator = ASTROGEOImageGenerator(os.getenv('HF_TOKEN'))\n",
    "print(\"‚úÖ ASTROGEO Image Generator ready with working models!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e98b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_636\\3179263850.py:63: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_636\\3179263850.py:63: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced Gradio interface created with fal.ai compatible models!\n"
     ]
    }
   ],
   "source": [
    "def create_enhanced_gradio_interface():\n",
    "    \"\"\"Create enhanced Gradio interface with image generation support\"\"\"\n",
    "    \n",
    "    # Custom CSS for better appearance\n",
    "    custom_css = \"\"\"\n",
    "    .gradio-container {\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;\n",
    "        max-width: 1200px !important;\n",
    "        margin: 0 auto !important;\n",
    "    }\n",
    "    .image-container {\n",
    "        border: 2px solid #e1e1e1;\n",
    "        border-radius: 10px;\n",
    "        padding: 10px;\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    .specialty-astronomy {\n",
    "        background: linear-gradient(45deg, #1a1a3e, #4a90e2);\n",
    "        color: white;\n",
    "        padding: 10px;\n",
    "        border-radius: 8px;\n",
    "        margin: 5px;\n",
    "    }\n",
    "    .specialty-geospatial {\n",
    "        background: linear-gradient(45deg, #1e4d2b, #27ae60);\n",
    "        color: white;\n",
    "        padding: 10px;\n",
    "        border-radius: 8px;\n",
    "        margin: 5px;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(css=custom_css, theme=\"soft\", title=\"üõ∞Ô∏è ASTROGEO AI Enhanced\") as interface:\n",
    "        \n",
    "        # Enhanced header\n",
    "        gr.HTML(\"\"\"\n",
    "        <div style='text-align: center; padding: 25px; background: linear-gradient(45deg, #1e3c72, #2a5298, #27ae60); border-radius: 15px; margin-bottom: 20px;'>\n",
    "            <h1 style='color: white; margin-bottom: 10px; font-size: 2.5em;'>üõ∞Ô∏è ASTROGEO AI ENHANCED</h1>\n",
    "            <p style='color: #e8f4ff; font-size: 1.2em; margin-bottom: 15px;'><strong>Multi-Platform Earth Observation + Image Generation</strong></p>\n",
    "            <div style='display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;'>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 12px; border-radius: 8px; min-width: 150px;'>\n",
    "                    <div style='font-size: 1.5em; margin-bottom: 5px;'>üåå</div>\n",
    "                    <div style='font-weight: bold;'>ASTRONOMY</div>\n",
    "                    <div style='font-size: 0.9em;'>Deep Space ‚Ä¢ Telescopes</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 12px; border-radius: 8px; min-width: 150px;'>\n",
    "                    <div style='font-size: 1.5em; margin-bottom: 5px;'>üõ∞Ô∏è</div>\n",
    "                    <div style='font-weight: bold;'>GEOSPATIAL</div>\n",
    "                    <div style='font-size: 0.9em;'>Earth Observation ‚Ä¢ GIS</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 12px; border-radius: 8px; min-width: 150px;'>\n",
    "                    <div style='font-size: 1.5em; margin-bottom: 5px;'>üé®</div>\n",
    "                    <div style='font-weight: bold;'>IMAGE AI</div>\n",
    "                    <div style='font-size: 0.9em;'>Advanced Visualization</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Main chat interface\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                chatbot = gr.Chatbot(\n",
    "                    label=\"ASTROGEO AI Assistant\",\n",
    "                    height=500,\n",
    "                    bubble_full_width=False,\n",
    "                    show_label=True\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    msg = gr.Textbox(\n",
    "                        label=\"Your Message\",\n",
    "                        placeholder=\"Ask about MOSDAC, VEDAS, BHUVAN data or request visualizations...\",\n",
    "                        lines=3,\n",
    "                        scale=4,\n",
    "                        show_label=False\n",
    "                    )\n",
    "                    submit_btn = gr.Button(\"üöÄ Send\", variant=\"primary\", scale=1, size=\"lg\")\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                # Image output area\n",
    "                image_output = gr.Image(\n",
    "                    label=\"Generated Visualization\",\n",
    "                    height=400,\n",
    "                    visible=False,\n",
    "                    show_label=True,\n",
    "                    container=True\n",
    "                )\n",
    "                \n",
    "                # Status display\n",
    "                status_display = gr.HTML(\n",
    "                    value=\"<div style='text-align: center; padding: 20px; color: #666;'>üí≠ Ready for your questions...</div>\",\n",
    "                    visible=True\n",
    "                )\n",
    "        \n",
    "        # Enhanced examples section\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.HTML(\"<h3 style='color: #4a90e2; text-align: center;'>üåå ASTRONOMY EXAMPLES</h3>\")\n",
    "                gr.Examples(\n",
    "                    examples=[\n",
    "                        \"Show me an image of the Andromeda Galaxy\",\n",
    "                        \"What are the different types of nebulae? Show me one.\",\n",
    "                        \"Create a visualization of Jupiter's moons\",\n",
    "                        \"Generate an image of the James Webb Space Telescope\",\n",
    "                        \"Visualize a black hole with accretion disk\"\n",
    "                    ],\n",
    "                    inputs=msg,\n",
    "                    label=\"Astronomy Examples\"\n",
    "                )\n",
    "            \n",
    "            with gr.Column():\n",
    "                gr.HTML(\"<h3 style='color: #27ae60; text-align: center;'>üõ∞Ô∏è GEOSPATIAL EXAMPLES</h3>\")\n",
    "                gr.Examples(\n",
    "                    examples=[\n",
    "                        \"Show me MOSDAC satellite data visualization\",\n",
    "                        \"Create an image of forest monitoring from VEDAS\",\n",
    "                        \"Generate BHUVAN mapping interface visualization\",\n",
    "                        \"Show me INSAT-3D weather satellite imagery\",\n",
    "                        \"Visualize Landsat agricultural monitoring\"\n",
    "                    ],\n",
    "                    inputs=msg,\n",
    "                    label=\"Geospatial Examples\"\n",
    "                )\n",
    "        \n",
    "        # Settings section with CORRECTED model choices\n",
    "        with gr.Accordion(\"‚öôÔ∏è Advanced Settings\", open=False):\n",
    "            with gr.Row():\n",
    "                model_choice = gr.Dropdown(\n",
    "                    choices=[\"flux\", \"flux_schnell\", \"recraft\", \"aura\"],  # ‚úÖ CORRECTED CHOICES\n",
    "                    value=\"flux\",\n",
    "                    label=\"Image Generation Model\",\n",
    "                    info=\"FLUX: Best quality | FLUX Schnell: Faster | Recraft: Technical diagrams | Aura: Alternative\"\n",
    "                )\n",
    "                enhance_prompts = gr.Checkbox(\n",
    "                    value=True,\n",
    "                    label=\"Enhanced Prompts\",\n",
    "                    info=\"Automatically optimize prompts for better results\"\n",
    "                )\n",
    "        \n",
    "        # Chat functionality with image support\n",
    "        def respond_with_images(message, history, model, enhance):\n",
    "            try:\n",
    "                # Process message with enhanced bot\n",
    "                text_response, generated_image = enhanced_astrogeo_bot.process_message_with_images(message, history)\n",
    "                \n",
    "                # Update chat history\n",
    "                history.append((message, text_response))\n",
    "                \n",
    "                # Update status and image display\n",
    "                if generated_image:\n",
    "                    # Determine specialty for status display\n",
    "                    specialty = enhanced_astrogeo_bot.image_gen.classify_image_type(message)\n",
    "                    \n",
    "                    if specialty == \"astronomy\":\n",
    "                        status_html = \"\"\"\n",
    "                        <div class='specialty-astronomy' style='text-align: center;'>\n",
    "                            <h3>üåå ASTRONOMY MODE ACTIVATED</h3>\n",
    "                            <p>Generated cosmic visualization with astronomical accuracy</p>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                    else:\n",
    "                        status_html = \"\"\"\n",
    "                        <div class='specialty-geospatial' style='text-align: center;'>\n",
    "                            <h3>üõ∞Ô∏è GEOSPATIAL MODE ACTIVATED</h3>\n",
    "                            <p>Generated Earth observation visualization</p>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                    \n",
    "                    return (\n",
    "                        history, \n",
    "                        \"\", \n",
    "                        generated_image, \n",
    "                        gr.update(visible=True), \n",
    "                        status_html\n",
    "                    )\n",
    "                else:\n",
    "                    # Text-only response\n",
    "                    status_html = \"<div style='text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px;'><h4>üí¨ Text Response Generated</h4><p>No image generation requested</p></div>\"\n",
    "                    \n",
    "                    return (\n",
    "                        history, \n",
    "                        \"\", \n",
    "                        None, \n",
    "                        gr.update(visible=False), \n",
    "                        status_html\n",
    "                    )\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = f\"‚ùå Error: {str(e)}\"\n",
    "                history.append((message, error_msg))\n",
    "                error_html = f\"<div style='color: red; text-align: center; padding: 10px;'><strong>Error:</strong> {str(e)}</div>\"\n",
    "                \n",
    "                return (\n",
    "                    history, \n",
    "                    \"\", \n",
    "                    None, \n",
    "                    gr.update(visible=False), \n",
    "                    error_html\n",
    "                )\n",
    "        \n",
    "        # Event handlers\n",
    "        submit_btn.click(\n",
    "            respond_with_images,\n",
    "            inputs=[msg, chatbot, model_choice, enhance_prompts],\n",
    "            outputs=[chatbot, msg, image_output, image_output, status_display],\n",
    "            queue=True\n",
    "        )\n",
    "        \n",
    "        msg.submit(\n",
    "            respond_with_images,\n",
    "            inputs=[msg, chatbot, model_choice, enhance_prompts],\n",
    "            outputs=[chatbot, msg, image_output, image_output, status_display],\n",
    "            queue=True\n",
    "        )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and store the enhanced interface\n",
    "enhanced_interface = create_enhanced_gradio_interface()\n",
    "print(\"‚úÖ Enhanced Gradio interface created with fal.ai compatible models!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "971f6d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ ASTROGEO AI Enhanced System is fully operational!\n",
      "üìä System Features:\n",
      "   ‚úÖ Multi-platform RAG (MOSDAC + VEDAS + BHUVAN)\n",
      "   ‚úÖ Advanced image generation (Astronomy + Geospatial)\n",
      "   ‚úÖ Smart specialty detection\n",
      "   ‚úÖ Professional Gradio interface\n",
      "   ‚úÖ Error handling and fallbacks\n",
      "   ‚úÖ Conversation memory\n",
      "   ‚úÖ Source attribution\n"
     ]
    }
   ],
   "source": [
    "# Test the enhanced system with sample queries\n",
    "def test_enhanced_system():\n",
    "    \"\"\"Test both text and image generation capabilities\"\"\"\n",
    "    \n",
    "    test_queries = [\n",
    "        # Text-only queries (should not generate images)\n",
    "        \"What types of data are available in MOSDAC?\",\n",
    "        \"How do I access VEDAS services?\",\n",
    "        \n",
    "        # Image generation queries (should generate images)\n",
    "        \"Show me a visualization of the Andromeda Galaxy\",\n",
    "        \"Generate an image of INSAT-3D satellite monitoring weather\",\n",
    "        \"Create a diagram of remote sensing workflow\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üß™ Testing Enhanced ASTROGEO AI System...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\nüîç Test {i}: {query}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Test the enhanced bot\n",
    "            text_response, image = enhanced_astrogeo_bot.process_message_with_images(query, [])\n",
    "            \n",
    "            print(f\"üìù Text Response: {text_response[:200]}...\")\n",
    "            \n",
    "            if image:\n",
    "                print(f\"üñºÔ∏è Image: Generated successfully!\")\n",
    "                # You can display the image here if needed\n",
    "                # display(image)\n",
    "            else:\n",
    "                print(f\"üí≠ Image: None (text-only response)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Testing complete!\")\n",
    "\n",
    "# Uncomment to run tests\n",
    "# test_enhanced_system()\n",
    "\n",
    "print(\"üéâ ASTROGEO AI Enhanced System is fully operational!\")\n",
    "print(\"üìä System Features:\")\n",
    "print(\"   ‚úÖ Multi-platform RAG (MOSDAC + VEDAS + BHUVAN)\")\n",
    "print(\"   ‚úÖ Advanced image generation (Astronomy + Geospatial)\")  \n",
    "print(\"   ‚úÖ Smart specialty detection\")\n",
    "print(\"   ‚úÖ Professional Gradio interface\")\n",
    "print(\"   ‚úÖ Error handling and fallbacks\")\n",
    "print(\"   ‚úÖ Conversation memory\")\n",
    "print(\"   ‚úÖ Source attribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b8c3064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_636\\1749286029.py:53: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_636\\1749286029.py:53: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced interface created!\n"
     ]
    }
   ],
   "source": [
    "def create_complete_astrogeo_interface():\n",
    "    \"\"\"Create complete ASTROGEO AI interface with all features\"\"\"\n",
    "    \n",
    "    custom_css = \"\"\"\n",
    "    .gradio-container {\n",
    "        font-family: 'Segoe UI', sans-serif !important;\n",
    "        max-width: 1400px !important;\n",
    "        margin: 0 auto !important;\n",
    "    }\n",
    "    .specialty-astronomy {\n",
    "        background: linear-gradient(45deg, #1a1a3e, #4a90e2);\n",
    "        color: white; padding: 15px; border-radius: 10px; text-align: center;\n",
    "    }\n",
    "    .specialty-geospatial {\n",
    "        background: linear-gradient(45deg, #1e4d2b, #27ae60);\n",
    "        color: white; padding: 15px; border-radius: 10px; text-align: center;\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(css=custom_css, theme=gr.themes.Soft(), title=\"üõ∞Ô∏è ASTROGEO AI Enhanced\") as interface:\n",
    "        \n",
    "        # Header\n",
    "        gr.HTML(\"\"\"\n",
    "        <div style='text-align: center; padding: 25px; background: linear-gradient(45deg, #1e3c72, #2a5298, #27ae60); border-radius: 15px; margin-bottom: 20px;'>\n",
    "            <h1 style='color: white; font-size: 2.5em; margin-bottom: 10px;'>üõ∞Ô∏è ASTROGEO AI ENHANCED</h1>\n",
    "            <p style='color: #e8f4ff; font-size: 1.2em; margin-bottom: 15px;'>\n",
    "                <strong>Multi-Platform Earth Observation + AI Assistant</strong>\n",
    "            </p>\n",
    "            <div style='display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;'>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 15px; border-radius: 10px; min-width: 180px;'>\n",
    "                    <div style='font-size: 1.8em;'>üåå</div>\n",
    "                    <div style='font-weight: bold;'>ASTRONOMY</div>\n",
    "                    <div style='font-size: 0.9em;'>Deep Space Objects</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 15px; border-radius: 10px; min-width: 180px;'>\n",
    "                    <div style='font-size: 1.8em;'>üõ∞Ô∏è</div>\n",
    "                    <div style='font-weight: bold;'>GEOSPATIAL</div>\n",
    "                    <div style='font-size: 0.9em;'>Earth Observation</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 15px; border-radius: 10px; min-width: 180px;'>\n",
    "                    <div style='font-size: 1.8em;'>ü§ñ</div>\n",
    "                    <div style='font-weight: bold;'>AI ASSISTANT</div>\n",
    "                    <div style='font-size: 0.9em;'>Smart RAG System</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Main Layout\n",
    "        with gr.Row():\n",
    "            # Chat Column\n",
    "            with gr.Column(scale=3):\n",
    "                chatbot = gr.Chatbot(\n",
    "                    label=\"ü§ñ ASTROGEO AI Assistant\",\n",
    "                    height=550,\n",
    "                    bubble_full_width=False,\n",
    "                    show_label=True,\n",
    "                    avatar_images=(\"üë§\", \"üõ∞Ô∏è\")\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    msg = gr.Textbox(\n",
    "                        placeholder=\"Ask about MOSDAC, VEDAS, BHUVAN data or space topics...\",\n",
    "                        lines=3,\n",
    "                        scale=4,\n",
    "                        show_label=False\n",
    "                    )\n",
    "                    with gr.Column(scale=1):\n",
    "                        send_btn = gr.Button(\"üöÄ Send\", variant=\"primary\", size=\"lg\")\n",
    "                        clear_btn = gr.Button(\"üóëÔ∏è Clear\", variant=\"secondary\")\n",
    "            \n",
    "            # Status Column\n",
    "            with gr.Column(scale=2):\n",
    "                status_display = gr.HTML(\n",
    "                    value=\"\"\"\n",
    "                    <div style='text-align: center; padding: 20px; background: #f8f9fa; border-radius: 10px; border: 1px solid #dee2e6;'>\n",
    "                        <h3 style='color: #495057; margin-bottom: 10px;'>üí≠ Ready for Questions</h3>\n",
    "                        <p style='color: #6c757d; margin: 0;'>Ask about space, satellites, or earth observation!</p>\n",
    "                    </div>\n",
    "                    \"\"\",\n",
    "                    visible=True\n",
    "                )\n",
    "        \n",
    "        # Examples Section\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.HTML(\"<h3 style='color: #4a90e2; text-align: center;'>üåå ASTRONOMY EXAMPLES</h3>\")\n",
    "                gr.Examples(\n",
    "                    examples=[\n",
    "                        \"What are pulsars and neutron stars?\",\n",
    "                        \"Tell me about the James Webb Space Telescope\",\n",
    "                        \"What are the different types of galaxies?\",\n",
    "                        \"Explain black holes and event horizons\",\n",
    "                        \"What is the lifecycle of a star?\"\n",
    "                    ],\n",
    "                    inputs=msg\n",
    "                )\n",
    "            \n",
    "            with gr.Column():\n",
    "                gr.HTML(\"<h3 style='color: #27ae60; text-align: center;'>üõ∞Ô∏è GEOSPATIAL EXAMPLES</h3>\")\n",
    "                gr.Examples(\n",
    "                    examples=[\n",
    "                        \"What types of data are available in MOSDAC?\",\n",
    "                        \"How do I access VEDAS services?\",\n",
    "                        \"What is BHUVAN and its applications?\",\n",
    "                        \"Tell me about INSAT-3D satellite data\",\n",
    "                        \"How to download satellite imagery?\"\n",
    "                    ],\n",
    "                    inputs=msg\n",
    "                )\n",
    "        \n",
    "        # Chat Functions\n",
    "        def respond(message, history):\n",
    "            if message.strip():\n",
    "                try:\n",
    "                    # Use your existing smart_bot function\n",
    "                    response = smart_bot(message, history)\n",
    "                    \n",
    "                    # Determine response type for status\n",
    "                    if any(word in message.lower() for word in [\"star\", \"galaxy\", \"planet\", \"space\", \"cosmic\"]):\n",
    "                        status_html = \"\"\"\n",
    "                        <div class='specialty-astronomy'>\n",
    "                            <h3>üåå ASTRONOMY MODE</h3>\n",
    "                            <p>Providing astronomical knowledge and insights</p>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                    elif any(word in message.lower() for word in [\"satellite\", \"mosdac\", \"vedas\", \"bhuvan\", \"earth\"]):\n",
    "                        status_html = \"\"\"\n",
    "                        <div class='specialty-geospatial'>\n",
    "                            <h3>üõ∞Ô∏è GEOSPATIAL MODE</h3>\n",
    "                            <p>Accessing earth observation knowledge base</p>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                    else:\n",
    "                        status_html = \"\"\"\n",
    "                        <div style='text-align: center; padding: 15px; background: #f8f9fa; border-radius: 10px;'>\n",
    "                            <h4>üí¨ General Response</h4>\n",
    "                            <p>Providing comprehensive information</p>\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                    \n",
    "                    history.append((message, response))\n",
    "                    return history, \"\", status_html\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_response = f\"‚ùå Error: {str(e)}\"\n",
    "                    history.append((message, error_response))\n",
    "                    error_status = f\"<div style='color: red; padding: 10px; text-align: center;'><strong>Error occurred</strong></div>\"\n",
    "                    return history, \"\", error_status\n",
    "            \n",
    "            return history, message, status_display.value\n",
    "        \n",
    "        def clear_chat():\n",
    "            return [], \"\"\n",
    "        \n",
    "        # Event Handlers\n",
    "        send_btn.click(respond, [msg, chatbot], [chatbot, msg, status_display])\n",
    "        msg.submit(respond, [msg, chatbot], [chatbot, msg, status_display])\n",
    "        clear_btn.click(clear_chat, outputs=[chatbot, msg])\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create interface\n",
    "enhanced_interface = create_complete_astrogeo_interface()\n",
    "print(\"‚úÖ Enhanced interface created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6ac2864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching Enhanced ASTROGEO AI Interface...\n",
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "* Running on public URL: https://2c5a189c3c7854fd95.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2c5a189c3c7854fd95.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced ASTROGEO AI Interface launched successfully!\n",
      "üåê Access your interface at: http://127.0.0.1:7863\n",
      "üîó Public link will be generated automatically\n"
     ]
    }
   ],
   "source": [
    "# Launch the enhanced interface\n",
    "print(\"üöÄ Launching Enhanced ASTROGEO AI Interface...\")\n",
    "\n",
    "try:\n",
    "    enhanced_interface.launch(\n",
    "        share=True,              # Creates public link\n",
    "        server_port=7863,        # Different port from your existing one\n",
    "        server_name=\"0.0.0.0\",   # Network accessible\n",
    "        show_error=True,\n",
    "        inbrowser=True,          # Auto-open in browser\n",
    "        auth=None                # No authentication\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Enhanced ASTROGEO AI Interface launched successfully!\")\n",
    "    print(\"üåê Access your interface at: http://127.0.0.1:7863\")\n",
    "    print(\"üîó Public link will be generated automatically\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Launch error: {e}\")\n",
    "    print(\"üîÑ Trying alternative port...\")\n",
    "    \n",
    "    # Fallback launch\n",
    "    enhanced_interface.launch(\n",
    "        share=True,\n",
    "        server_port=7864,\n",
    "        show_error=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "259274ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Image generation integration ready!\n"
     ]
    }
   ],
   "source": [
    "# Add HF_TOKEN and Image Generator Integration\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-hugging-face-token')\n",
    "\n",
    "# Simple Image Generator\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "def generate_image_if_requested(message, response):\n",
    "    \"\"\"Check if image is requested and generate it\"\"\"\n",
    "    image_triggers = [\"generate\", \"image\", \"show me\", \"visualize\", \"create\", \"picture\", \"photo\"]\n",
    "    \n",
    "    if any(trigger in message.lower() for trigger in image_triggers):\n",
    "        try:\n",
    "            # Initialize client\n",
    "            client = InferenceClient(provider=\"fal-ai\", api_key=os.getenv('HF_TOKEN'))\n",
    "            \n",
    "            # Generate image\n",
    "            image = client.text_to_image(\n",
    "                prompt=f\"High-resolution astronomical image of {message}\",\n",
    "                model=\"black-forest-labs/FLUX.1-dev\"\n",
    "            )\n",
    "            \n",
    "            enhanced_response = f\"{response}\\n\\nüì∏ **‚úÖ Generated astronomical visualization!**\"\n",
    "            return enhanced_response, image\n",
    "            \n",
    "        except Exception as e:\n",
    "            enhanced_response = f\"{response}\\n\\nüì∏ **‚ùå Image generation failed: {str(e)}**\"\n",
    "            return enhanced_response, None\n",
    "    \n",
    "    return response, None\n",
    "\n",
    "# Update your interface response function\n",
    "def updated_respond(message, history):\n",
    "    if message.strip():\n",
    "        try:\n",
    "            # Get text response\n",
    "            text_response = smart_bot(message, history)\n",
    "            \n",
    "            # Try to generate image if requested\n",
    "            enhanced_response, generated_image = generate_image_if_requested(message, text_response)\n",
    "            \n",
    "            history.append((message, enhanced_response))\n",
    "            \n",
    "            # Return status based on generation\n",
    "            if generated_image:\n",
    "                status_html = \"\"\"\n",
    "                <div class='specialty-astronomy'>\n",
    "                    <h3>üåå IMAGE GENERATED!</h3>\n",
    "                    <p>Created astronomical visualization</p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            else:\n",
    "                status_html = \"\"\"\n",
    "                <div style='text-align: center; padding: 15px; background: #f8f9fa; border-radius: 10px;'>\n",
    "                    <h4>üí¨ Text Response</h4>\n",
    "                    <p>Comprehensive information provided</p>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            \n",
    "            return history, \"\", status_html\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_response = f\"‚ùå Error: {str(e)}\"\n",
    "            history.append((message, error_response))\n",
    "            return history, \"\", \"<div style='color: red;'>Error occurred</div>\"\n",
    "    \n",
    "    return history, message, \"\"\n",
    "\n",
    "print(\"‚úÖ Image generation integration ready!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
